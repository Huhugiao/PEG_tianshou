Loading agent under performance_test_catch0310
Successfully restore policy and optim.
Successfully restore buffer.
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #158: 10240it [00:14, 715.92it/s, env_step=1617920, len=29, loss=-0.016, loss/clip=-0.009, loss/ent=0.246, loss/vf=0.001, n/ep=11, n/st=256, rew=17.99]         
Epoch #158: test_reward: 18.119212 Â± 0.022031, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #159: 10240it [00:14, 713.25it/s, env_step=1628160, len=29, loss=-0.014, loss/clip=-0.007, loss/ent=0.224, loss/vf=0.001, n/ep=2, n/st=256, rew=18.02]          
Epoch #159: test_reward: 18.088521 Â± 0.014616, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #160: 10240it [00:15, 674.85it/s, env_step=1638400, len=29, loss=-0.012, loss/clip=-0.007, loss/ent=0.193, loss/vf=0.001, n/ep=10, n/st=256, rew=18.02]         
Epoch #160: test_reward: 18.066789 Â± 0.023572, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #161: 10240it [00:17, 585.66it/s, env_step=1648640, len=29, loss=-0.016, loss/clip=-0.009, loss/ent=0.233, loss/vf=0.001, n/ep=8, n/st=256, rew=17.96]          
Epoch #161: test_reward: 17.984216 Â± 0.050508, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #162: 10240it [00:17, 598.31it/s, env_step=1658880, len=29, loss=-0.014, loss/clip=-0.008, loss/ent=0.220, loss/vf=0.000, n/ep=7, n/st=256, rew=17.93]          
Epoch #162: test_reward: 18.002527 Â± 0.023366, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #163: 10240it [00:18, 547.07it/s, env_step=1669120, len=29, loss=-0.012, loss/clip=-0.006, loss/ent=0.188, loss/vf=0.000, n/ep=8, n/st=256, rew=18.00]          
Epoch #163: test_reward: 17.972630 Â± 0.050375, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #164: 10240it [00:18, 555.80it/s, env_step=1679360, len=29, loss=-0.011, loss/clip=-0.005, loss/ent=0.194, loss/vf=0.000, n/ep=7, n/st=256, rew=17.94]          
Epoch #164: test_reward: 17.940530 Â± 0.028068, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #165: 10240it [00:19, 513.17it/s, env_step=1689600, len=29, loss=-0.012, loss/clip=-0.006, loss/ent=0.215, loss/vf=0.000, n/ep=6, n/st=256, rew=18.01]          
Epoch #165: test_reward: 17.973912 Â± 0.025620, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #166: 10240it [00:20, 495.11it/s, env_step=1699840, len=29, loss=-0.012, loss/clip=-0.006, loss/ent=0.190, loss/vf=0.000, n/ep=7, n/st=256, rew=18.03]          
Epoch #166: test_reward: 17.995435 Â± 0.046380, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #167: 10240it [00:21, 478.40it/s, env_step=1710080, len=29, loss=-0.016, loss/clip=-0.009, loss/ent=0.236, loss/vf=0.001, n/ep=5, n/st=256, rew=17.99]          
Epoch #167: test_reward: 17.990524 Â± 0.054456, best_reward: 18.119212 Â± 0.022031 in #158
Epoch #168: 10240it [00:22, 453.95it/s, env_step=1720320, len=29, loss=-0.014, loss/clip=-0.008, loss/ent=0.210, loss/vf=0.000, n/ep=4, n/st=256, rew=18.04]          
Epoch #168: test_reward: 18.141420 Â± 0.030254, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #169: 10240it [00:22, 450.98it/s, env_step=1730560, len=29, loss=-0.014, loss/clip=-0.008, loss/ent=0.184, loss/vf=0.001, n/ep=6, n/st=256, rew=18.03]          
Epoch #169: test_reward: 18.045237 Â± 0.060987, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #170: 10240it [00:24, 421.72it/s, env_step=1740800, len=29, loss=-0.011, loss/clip=-0.005, loss/ent=0.192, loss/vf=0.001, n/ep=8, n/st=256, rew=18.05]          
Epoch #170: test_reward: 18.047347 Â± 0.056619, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #171: 10240it [00:25, 396.73it/s, env_step=1751040, len=29, loss=-0.015, loss/clip=-0.009, loss/ent=0.229, loss/vf=0.001, n/ep=6, n/st=256, rew=17.94]          
Epoch #171: test_reward: 17.945585 Â± 0.060539, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #172: 10240it [00:26, 392.16it/s, env_step=1761280, len=29, loss=-0.012, loss/clip=-0.007, loss/ent=0.181, loss/vf=0.000, n/ep=7, n/st=256, rew=17.93]          
Epoch #172: test_reward: 17.974107 Â± 0.052528, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #173: 10240it [00:26, 381.76it/s, env_step=1771520, len=29, loss=-0.013, loss/clip=-0.007, loss/ent=0.205, loss/vf=0.000, n/ep=5, n/st=256, rew=18.04]          
Epoch #173: test_reward: 17.987868 Â± 0.062301, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #174: 10240it [00:27, 373.35it/s, env_step=1781760, len=29, loss=-0.011, loss/clip=-0.005, loss/ent=0.188, loss/vf=0.000, n/ep=7, n/st=256, rew=18.05]          
Epoch #174: test_reward: 18.028350 Â± 0.034728, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #175: 10240it [00:28, 362.94it/s, env_step=1792000, len=29, loss=-0.009, loss/clip=-0.005, loss/ent=0.141, loss/vf=0.000, n/ep=6, n/st=256, rew=17.97]          
Epoch #175: test_reward: 17.975438 Â± 0.023506, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #176: 10240it [00:28, 354.38it/s, env_step=1802240, len=29, loss=-0.014, loss/clip=-0.007, loss/ent=0.253, loss/vf=0.000, n/ep=6, n/st=256, rew=18.05]          
Epoch #176: test_reward: 18.004211 Â± 0.032038, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #177: 10240it [00:30, 337.49it/s, env_step=1812480, len=29, loss=-0.011, loss/clip=-0.006, loss/ent=0.180, loss/vf=0.000, n/ep=7, n/st=256, rew=17.99]          
Epoch #177: test_reward: 17.987150 Â± 0.095526, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #178: 10240it [00:30, 334.08it/s, env_step=1822720, len=29, loss=-0.011, loss/clip=-0.006, loss/ent=0.183, loss/vf=0.000, n/ep=7, n/st=256, rew=18.04]          
Epoch #178: test_reward: 18.045572 Â± 0.061742, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #179: 10240it [00:32, 318.87it/s, env_step=1832960, len=29, loss=-0.015, loss/clip=-0.007, loss/ent=0.264, loss/vf=0.000, n/ep=8, n/st=256, rew=18.07]          
Epoch #179: test_reward: 18.058484 Â± 0.023708, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #180: 10240it [00:31, 320.42it/s, env_step=1843200, len=29, loss=-0.013, loss/clip=-0.010, loss/ent=0.285, loss/vf=0.019, n/ep=6, n/st=256, rew=18.03]          
Epoch #180: test_reward: 18.060568 Â± 0.013325, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #181: 10240it [00:33, 303.58it/s, env_step=1853440, len=29, loss=-0.012, loss/clip=-0.006, loss/ent=0.178, loss/vf=0.000, n/ep=9, n/st=256, rew=18.06]          
Epoch #181: test_reward: 18.083833 Â± 0.044462, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #182: 10240it [32:20,  5.28it/s, env_step=1863680, len=29, loss=-0.011, loss/clip=-0.005, loss/ent=0.192, loss/vf=0.000, n/ep=13, n/st=256, rew=18.00]          
Epoch #182: test_reward: 18.023083 Â± 0.023171, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #183: 10240it [00:39, 261.80it/s, env_step=1873920, len=29, loss=-0.015, loss/clip=-0.008, loss/ent=0.239, loss/vf=0.001, n/ep=13, n/st=256, rew=17.99]         
Epoch #183: test_reward: 17.929658 Â± 0.054200, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #184: 10240it [00:35, 287.67it/s, env_step=1884160, len=29, loss=-0.014, loss/clip=-0.007, loss/ent=0.249, loss/vf=0.000, n/ep=13, n/st=256, rew=17.97]         
Epoch #184: test_reward: 17.968832 Â± 0.063683, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #185: 10240it [00:36, 282.34it/s, env_step=1894400, len=29, loss=-0.013, loss/clip=-0.007, loss/ent=0.191, loss/vf=0.000, n/ep=12, n/st=256, rew=18.05]         
Epoch #185: test_reward: 18.050813 Â± 0.080892, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #186: 10240it [00:36, 279.50it/s, env_step=1904640, len=29, loss=-0.016, loss/clip=-0.008, loss/ent=0.263, loss/vf=0.000, n/ep=11, n/st=256, rew=17.98]         
Epoch #186: test_reward: 17.969094 Â± 0.056198, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #187: 10240it [00:37, 271.50it/s, env_step=1914880, len=29, loss=-0.015, loss/clip=-0.008, loss/ent=0.227, loss/vf=0.001, n/ep=14, n/st=256, rew=17.99]         
Epoch #187: test_reward: 18.002719 Â± 0.084888, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #188: 10240it [00:40, 252.67it/s, env_step=1925120, len=29, loss=-0.013, loss/clip=-0.007, loss/ent=0.207, loss/vf=0.000, n/ep=14, n/st=256, rew=17.96]         
Epoch #188: test_reward: 17.917460 Â± 0.074713, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #189: 10240it [00:38, 264.08it/s, env_step=1935360, len=29, loss=-0.016, loss/clip=-0.009, loss/ent=0.253, loss/vf=0.001, n/ep=15, n/st=256, rew=18.00]         
Epoch #189: test_reward: 18.012440 Â± 0.034291, best_reward: 18.141420 Â± 0.030254 in #168
Epoch #190:  10%|1| 1024/10000 [00:04<00:34, 259.38it/s, env_step=1936384, len=29, loss=-0.015, loss/clip=-0.007, loss/ent=0.256, loss/vf=0.000, n/ep=11, n/st=256, re
