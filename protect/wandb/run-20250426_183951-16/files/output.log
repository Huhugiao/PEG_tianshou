Epoch #1: 10240it [00:11, 889.75it/s, env_step=10240, len=196, loss=0.141, loss/clip=-0.001, loss/ent=3.170, loss/vf=0.695, n/ep=0, n/st=256, rew=-76.97]                                                               
Epoch #1: test_reward: -84.149425 Â± 14.756287, best_reward: -80.276583 Â± 16.467114 in #0
Epoch #2: 10240it [00:09, 1072.43it/s, env_step=20480, len=345, loss=0.062, loss/clip=-0.002, loss/ent=3.158, loss/vf=0.383, n/ep=1, n/st=256, rew=-98.58]                                                              
Epoch #2: test_reward: -68.812082 Â± 6.433336, best_reward: -68.812082 Â± 6.433336 in #2
Epoch #3: 10240it [00:08, 1145.81it/s, env_step=30720, len=100, loss=0.116, loss/clip=-0.004, loss/ent=3.101, loss/vf=0.602, n/ep=1, n/st=256, rew=-63.00]                                                              
Epoch #3: test_reward: -74.261673 Â± 9.959801, best_reward: -68.812082 Â± 6.433336 in #2
Epoch #4: 10240it [00:09, 1055.11it/s, env_step=40960, len=145, loss=0.094, loss/clip=-0.003, loss/ent=3.144, loss/vf=0.514, n/ep=6, n/st=256, rew=-76.06]                                                              
Epoch #4: test_reward: -62.903234 Â± 39.853616, best_reward: -62.903234 Â± 39.853616 in #4
Epoch #5: 10240it [00:10, 987.81it/s, env_step=51200, len=260, loss=0.109, loss/clip=-0.003, loss/ent=3.099, loss/vf=0.573, n/ep=2, n/st=256, rew=-36.25]                                                               
Epoch #5: test_reward: -77.918539 Â± 10.720297, best_reward: -62.903234 Â± 39.853616 in #4
tracker requires_grad=True, has non-zero gradients=True
target requires_grad=True, has non-zero gradients=False
Training target policy with epoch 5
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #6: 10240it [00:12, 822.68it/s, env_step=61440, len=446, loss=-0.041, loss/clip=-0.012, loss/ent=2.982, loss/vf=0.004, n/ep=0, n/st=256, rew=28.73]                                                               
Epoch #6: test_reward: -42.097840 Â± 36.567449, best_reward: 70.990832 Â± 107.687355 in #5
tracker requires_grad=True, has non-zero gradients=False
target requires_grad=True, has non-zero gradients=True
Training tracker policy with epoch 10
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #6: 10240it [00:10, 991.54it/s, env_step=61440, len=805, loss=0.318, loss/clip=-0.008, loss/ent=3.064, loss/vf=1.425, n/ep=0, n/st=256, rew=-27.61]                                                               
Epoch #6: test_reward: -155.370974 Â± 63.819985, best_reward: -155.370974 Â± 63.819985 in #6
Epoch #7: 10240it [00:08, 1247.31it/s, env_step=71680, len=140, loss=1.124, loss/clip=-0.008, loss/ent=3.017, loss/vf=4.650, n/ep=2, n/st=256, rew=53.44]                                                               
Epoch #7: test_reward: 62.765346 Â± 8.102223, best_reward: 62.765346 Â± 8.102223 in #7
Epoch #8: 10240it [00:08, 1195.21it/s, env_step=81920, len=119, loss=0.269, loss/clip=-0.011, loss/ent=2.967, loss/vf=1.237, n/ep=0, n/st=256, rew=53.17]                                                               
Epoch #8: test_reward: 89.952709 Â± 12.872451, best_reward: 89.952709 Â± 12.872451 in #8
Epoch #9: 10240it [00:08, 1238.63it/s, env_step=92160, len=136, loss=0.272, loss/clip=-0.010, loss/ent=2.841, loss/vf=1.241, n/ep=0, n/st=256, rew=60.66]                                                               
Epoch #9: test_reward: 67.705135 Â± 26.960259, best_reward: 89.952709 Â± 12.872451 in #8
Epoch #10: 10240it [00:08, 1165.40it/s, env_step=102400, len=185, loss=0.312, loss/clip=-0.009, loss/ent=2.840, loss/vf=1.400, n/ep=4, n/st=256, rew=70.13]                                                             
Epoch #10: test_reward: 57.983462 Â± 2.279295, best_reward: 89.952709 Â± 12.872451 in #8
tracker requires_grad=True, has non-zero gradients=True
target requires_grad=True, has non-zero gradients=False
Training target policy with epoch 10
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #10: 10240it [00:09, 1059.20it/s, env_step=102400, len=853, loss=0.105, loss/clip=-0.008, loss/ent=2.986, loss/vf=0.571, n/ep=0, n/st=256, rew=-69.48]                                                            
Epoch #10: test_reward: -68.172394 Â± 9.376752, best_reward: -56.940632 Â± 11.802543 in #9
tracker requires_grad=True, has non-zero gradients=False
target requires_grad=True, has non-zero gradients=True
Training tracker policy with epoch 15
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #10: 10240it [00:09, 1137.66it/s, env_step=102400, len=77, loss=0.092, loss/clip=-0.013, loss/ent=2.845, loss/vf=0.532, n/ep=0, n/st=256, rew=56.62]                                                              
Epoch #10: test_reward: 50.833959 Â± 7.395157, best_reward: 66.612025 Â± 69.821413 in #9
Epoch #11: 10240it [00:09, 1128.76it/s, env_step=112640, len=88, loss=0.125, loss/clip=-0.011, loss/ent=2.718, loss/vf=0.649, n/ep=2, n/st=256, rew=58.69]                                                              
Epoch #11: test_reward: 59.531689 Â± 17.942581, best_reward: 66.612025 Â± 69.821413 in #9
Epoch #12: 10240it [00:08, 1145.78it/s, env_step=122880, len=110, loss=0.054, loss/clip=-0.010, loss/ent=2.755, loss/vf=0.366, n/ep=0, n/st=256, rew=61.37]                                                             
Epoch #12: test_reward: 61.914691 Â± 10.240562, best_reward: 66.612025 Â± 69.821413 in #9
Epoch #13: 10240it [00:08, 1141.58it/s, env_step=133120, len=107, loss=0.077, loss/clip=-0.013, loss/ent=2.699, loss/vf=0.467, n/ep=5, n/st=256, rew=54.50]                                                             
Epoch #13: test_reward: 57.502531 Â± 5.253130, best_reward: 66.612025 Â± 69.821413 in #9
Epoch #14: 10240it [00:07, 1314.70it/s, env_step=143360, len=93, loss=0.070, loss/clip=-0.015, loss/ent=2.361, loss/vf=0.434, n/ep=7, n/st=256, rew=59.18]                                                              
Epoch #14: test_reward: 58.487693 Â± 3.177547, best_reward: 66.612025 Â± 69.821413 in #9
Epoch #15: 10240it [00:08, 1211.14it/s, env_step=153600, len=55, loss=0.037, loss/clip=-0.010, loss/ent=1.893, loss/vf=0.267, n/ep=2, n/st=256, rew=51.97]                                                              
Epoch #15: test_reward: 50.395853 Â± 1.816429, best_reward: 66.612025 Â± 69.821413 in #9
tracker requires_grad=True, has non-zero gradients=True
target requires_grad=True, has non-zero gradients=False
Training target policy with epoch 15
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #14: 10240it [00:09, 1085.66it/s, env_step=143360, len=97, loss=0.099, loss/clip=-0.004, loss/ent=3.162, loss/vf=0.540, n/ep=2, n/st=256, rew=-57.64]                                                             
Epoch #14: test_reward: -49.288430 Â± 0.717290, best_reward: -49.288430 Â± 0.717290 in #14
Epoch #15:  46%|####################2                       | 4608/10000 [00:03<00:03, 1458.99it/s, env_step=147968, len=128, loss=0.046, loss/clip=-0.009, loss/ent=2.713, loss/vf=0.332, n/ep=3, n/st=256, rew=-51.33]
