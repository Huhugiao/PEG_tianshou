Epoch #1: 10240it [00:10, 953.68it/s, env_step=10240, len=227, loss=0.179, loss/clip=-0.007, loss/ent=2.945, loss/vf=0.861, n/ep=3, n/st=256, rew=-51.42]                                                               
Epoch #1: test_reward: -76.534509 Â± 7.946058, best_reward: -73.180349 Â± 12.995644 in #0
Epoch #2: 10240it [00:09, 1093.58it/s, env_step=20480, len=319, loss=0.029, loss/clip=-0.003, loss/ent=2.990, loss/vf=0.248, n/ep=1, n/st=256, rew=-94.96]                                                              
Epoch #2: test_reward: -75.012566 Â± 10.822761, best_reward: -73.180349 Â± 12.995644 in #0
Epoch #3: 10240it [00:09, 1097.26it/s, env_step=30720, len=91, loss=0.122, loss/clip=-0.004, loss/ent=3.103, loss/vf=0.626, n/ep=1, n/st=256, rew=-66.59]                                                               
Epoch #3: test_reward: -60.389238 Â± 35.328350, best_reward: -60.389238 Â± 35.328350 in #3
Epoch #4: 10240it [00:09, 1054.49it/s, env_step=40960, len=168, loss=0.106, loss/clip=-0.004, loss/ent=3.065, loss/vf=0.562, n/ep=3, n/st=256, rew=-73.21]                                                              
Epoch #4: test_reward: -79.129046 Â± 13.537220, best_reward: -60.389238 Â± 35.328350 in #3
Epoch #5: 10240it [00:09, 1044.85it/s, env_step=51200, len=87, loss=0.090, loss/clip=-0.002, loss/ent=3.101, loss/vf=0.491, n/ep=3, n/st=256, rew=-61.69]                                                               
Epoch #5: test_reward: -63.607882 Â± 33.943927, best_reward: -60.389238 Â± 35.328350 in #3
tracker requires_grad=True, has non-zero gradients=True
target requires_grad=True, has non-zero gradients=False
Training target policy with epoch 10
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #4: 10240it [00:11, 873.37it/s, env_step=40960, len=473, loss=-0.033, loss/clip=-0.008, loss/ent=2.584, loss/vf=0.003, n/ep=0, n/st=256, rew=-0.75]                                                               
Epoch #4: test_reward: 168.707872 Â± 22.833405, best_reward: 187.642522 Â± 102.597067 in #3
Epoch #5: 10240it [00:08, 1186.16it/s, env_step=51200, len=1000, loss=-0.035, loss/clip=-0.007, loss/ent=2.920, loss/vf=0.002, n/ep=0, n/st=256, rew=198.98]                                                            
Epoch #5: test_reward: 162.626694 Â± 42.523368, best_reward: 187.642522 Â± 102.597067 in #3
Epoch #6: 10240it [00:08, 1209.02it/s, env_step=61440, len=811, loss=0.170, loss/clip=-0.011, loss/ent=2.956, loss/vf=0.841, n/ep=0, n/st=256, rew=214.22]                                                              
Epoch #6: test_reward: 149.983045 Â± 104.318709, best_reward: 187.642522 Â± 102.597067 in #3
Epoch #7: 10240it [00:08, 1168.73it/s, env_step=71680, len=795, loss=0.353, loss/clip=-0.012, loss/ent=2.476, loss/vf=1.559, n/ep=0, n/st=256, rew=68.18]                                                               
Epoch #7: test_reward: 256.711039 Â± 27.024424, best_reward: 256.711039 Â± 27.024424 in #7
Epoch #8: 10240it [00:08, 1173.95it/s, env_step=81920, len=549, loss=1.172, loss/clip=-0.014, loss/ent=2.694, loss/vf=4.852, n/ep=2, n/st=256, rew=163.63]                                                              
Epoch #8: test_reward: 84.807351 Â± 14.494496, best_reward: 256.711039 Â± 27.024424 in #7
Epoch #9: 10240it [00:07, 1360.82it/s, env_step=92160, len=77, loss=0.574, loss/clip=-0.009, loss/ent=2.436, loss/vf=2.431, n/ep=2, n/st=256, rew=61.32]                                                                
Epoch #9: test_reward: 12.486993 Â± 51.322642, best_reward: 256.711039 Â± 27.024424 in #7
Epoch #10: 10240it [00:07, 1350.28it/s, env_step=102400, len=106, loss=0.342, loss/clip=-0.005, loss/ent=2.884, loss/vf=1.503, n/ep=0, n/st=256, rew=68.37]                                                             
Epoch #10: test_reward: 63.348581 Â± 2.619824, best_reward: 256.711039 Â± 27.024424 in #7
tracker requires_grad=True, has non-zero gradients=False
target requires_grad=True, has non-zero gradients=True
Training tracker policy with epoch 15
Loading agent under protect_vs_invade
[34m[1mwandb[0m:   1 of 1 files downloaded.
Epoch #10: 10240it [00:10, 1010.27it/s, env_step=102400, len=207, loss=0.080, loss/clip=-0.003, loss/ent=3.112, loss/vf=0.454, n/ep=0, n/st=256, rew=-87.90]                                                            
Epoch #10: test_reward: -226.281709 Â± 143.156998, best_reward: -24.537872 Â± 50.578880 in #9
Epoch #11: 10240it [00:07, 1280.62it/s, env_step=112640, len=164, loss=0.007, loss/clip=-0.004, loss/ent=3.089, loss/vf=0.168, n/ep=0, n/st=256, rew=40.97]                                                             
